{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "torch.manual_seed(1)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<torch._C.Generator at 0x7ff7d940b6f0>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "CONTEXT_SIZE = 2\n",
                "EMBEDDING_DIM = 10"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
                "And dig deep trenches in thy beauty's field,\n",
                "Thy youth's proud livery so gazed on now,\n",
                "Will be a totter'd weed of small worth held:\n",
                "Then being asked, where all thy beauty lies,\n",
                "Where all the treasure of thy lusty days;\n",
                "To say, within thine own deep sunken eyes,\n",
                "Were an all-eating shame, and thriftless praise.\n",
                "How much more praise deserv'd thy beauty's use,\n",
                "If thou couldst answer 'This fair child of mine\n",
                "Shall sum my count, and make my old excuse,'\n",
                "Proving his beauty by succession thine!\n",
                "This were to be new made when thou art old,\n",
                "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "ngrams = [\n",
                "    (\n",
                "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
                "        test_sentence[i]\n",
                "    )\n",
                "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
                "]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "ngrams"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[(['forty', 'When'], 'winters'),\n",
                            " (['winters', 'forty'], 'shall'),\n",
                            " (['shall', 'winters'], 'besiege'),\n",
                            " (['besiege', 'shall'], 'thy'),\n",
                            " (['thy', 'besiege'], 'brow,'),\n",
                            " (['brow,', 'thy'], 'And'),\n",
                            " (['And', 'brow,'], 'dig'),\n",
                            " (['dig', 'And'], 'deep'),\n",
                            " (['deep', 'dig'], 'trenches'),\n",
                            " (['trenches', 'deep'], 'in'),\n",
                            " (['in', 'trenches'], 'thy'),\n",
                            " (['thy', 'in'], \"beauty's\"),\n",
                            " ([\"beauty's\", 'thy'], 'field,'),\n",
                            " (['field,', \"beauty's\"], 'Thy'),\n",
                            " (['Thy', 'field,'], \"youth's\"),\n",
                            " ([\"youth's\", 'Thy'], 'proud'),\n",
                            " (['proud', \"youth's\"], 'livery'),\n",
                            " (['livery', 'proud'], 'so'),\n",
                            " (['so', 'livery'], 'gazed'),\n",
                            " (['gazed', 'so'], 'on'),\n",
                            " (['on', 'gazed'], 'now,'),\n",
                            " (['now,', 'on'], 'Will'),\n",
                            " (['Will', 'now,'], 'be'),\n",
                            " (['be', 'Will'], 'a'),\n",
                            " (['a', 'be'], \"totter'd\"),\n",
                            " ([\"totter'd\", 'a'], 'weed'),\n",
                            " (['weed', \"totter'd\"], 'of'),\n",
                            " (['of', 'weed'], 'small'),\n",
                            " (['small', 'of'], 'worth'),\n",
                            " (['worth', 'small'], 'held:'),\n",
                            " (['held:', 'worth'], 'Then'),\n",
                            " (['Then', 'held:'], 'being'),\n",
                            " (['being', 'Then'], 'asked,'),\n",
                            " (['asked,', 'being'], 'where'),\n",
                            " (['where', 'asked,'], 'all'),\n",
                            " (['all', 'where'], 'thy'),\n",
                            " (['thy', 'all'], 'beauty'),\n",
                            " (['beauty', 'thy'], 'lies,'),\n",
                            " (['lies,', 'beauty'], 'Where'),\n",
                            " (['Where', 'lies,'], 'all'),\n",
                            " (['all', 'Where'], 'the'),\n",
                            " (['the', 'all'], 'treasure'),\n",
                            " (['treasure', 'the'], 'of'),\n",
                            " (['of', 'treasure'], 'thy'),\n",
                            " (['thy', 'of'], 'lusty'),\n",
                            " (['lusty', 'thy'], 'days;'),\n",
                            " (['days;', 'lusty'], 'To'),\n",
                            " (['To', 'days;'], 'say,'),\n",
                            " (['say,', 'To'], 'within'),\n",
                            " (['within', 'say,'], 'thine'),\n",
                            " (['thine', 'within'], 'own'),\n",
                            " (['own', 'thine'], 'deep'),\n",
                            " (['deep', 'own'], 'sunken'),\n",
                            " (['sunken', 'deep'], 'eyes,'),\n",
                            " (['eyes,', 'sunken'], 'Were'),\n",
                            " (['Were', 'eyes,'], 'an'),\n",
                            " (['an', 'Were'], 'all-eating'),\n",
                            " (['all-eating', 'an'], 'shame,'),\n",
                            " (['shame,', 'all-eating'], 'and'),\n",
                            " (['and', 'shame,'], 'thriftless'),\n",
                            " (['thriftless', 'and'], 'praise.'),\n",
                            " (['praise.', 'thriftless'], 'How'),\n",
                            " (['How', 'praise.'], 'much'),\n",
                            " (['much', 'How'], 'more'),\n",
                            " (['more', 'much'], 'praise'),\n",
                            " (['praise', 'more'], \"deserv'd\"),\n",
                            " ([\"deserv'd\", 'praise'], 'thy'),\n",
                            " (['thy', \"deserv'd\"], \"beauty's\"),\n",
                            " ([\"beauty's\", 'thy'], 'use,'),\n",
                            " (['use,', \"beauty's\"], 'If'),\n",
                            " (['If', 'use,'], 'thou'),\n",
                            " (['thou', 'If'], 'couldst'),\n",
                            " (['couldst', 'thou'], 'answer'),\n",
                            " (['answer', 'couldst'], \"'This\"),\n",
                            " ([\"'This\", 'answer'], 'fair'),\n",
                            " (['fair', \"'This\"], 'child'),\n",
                            " (['child', 'fair'], 'of'),\n",
                            " (['of', 'child'], 'mine'),\n",
                            " (['mine', 'of'], 'Shall'),\n",
                            " (['Shall', 'mine'], 'sum'),\n",
                            " (['sum', 'Shall'], 'my'),\n",
                            " (['my', 'sum'], 'count,'),\n",
                            " (['count,', 'my'], 'and'),\n",
                            " (['and', 'count,'], 'make'),\n",
                            " (['make', 'and'], 'my'),\n",
                            " (['my', 'make'], 'old'),\n",
                            " (['old', 'my'], \"excuse,'\"),\n",
                            " ([\"excuse,'\", 'old'], 'Proving'),\n",
                            " (['Proving', \"excuse,'\"], 'his'),\n",
                            " (['his', 'Proving'], 'beauty'),\n",
                            " (['beauty', 'his'], 'by'),\n",
                            " (['by', 'beauty'], 'succession'),\n",
                            " (['succession', 'by'], 'thine!'),\n",
                            " (['thine!', 'succession'], 'This'),\n",
                            " (['This', 'thine!'], 'were'),\n",
                            " (['were', 'This'], 'to'),\n",
                            " (['to', 'were'], 'be'),\n",
                            " (['be', 'to'], 'new'),\n",
                            " (['new', 'be'], 'made'),\n",
                            " (['made', 'new'], 'when'),\n",
                            " (['when', 'made'], 'thou'),\n",
                            " (['thou', 'when'], 'art'),\n",
                            " (['art', 'thou'], 'old,'),\n",
                            " (['old,', 'art'], 'And'),\n",
                            " (['And', 'old,'], 'see'),\n",
                            " (['see', 'And'], 'thy'),\n",
                            " (['thy', 'see'], 'blood'),\n",
                            " (['blood', 'thy'], 'warm'),\n",
                            " (['warm', 'blood'], 'when'),\n",
                            " (['when', 'warm'], 'thou'),\n",
                            " (['thou', 'when'], \"feel'st\"),\n",
                            " ([\"feel'st\", 'thou'], 'it'),\n",
                            " (['it', \"feel'st\"], 'cold.')]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 8
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "vocab = set(test_sentence)\n",
                "word_to_ix = {word: i for i, word in enumerate(vocab)}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "word_to_ix"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'so': 0,\n",
                            " 'made': 1,\n",
                            " 'now,': 2,\n",
                            " \"'This\": 3,\n",
                            " 'the': 4,\n",
                            " 'days;': 5,\n",
                            " 'couldst': 6,\n",
                            " 'livery': 7,\n",
                            " 'Will': 8,\n",
                            " 'mine': 9,\n",
                            " 'old,': 10,\n",
                            " 'and': 11,\n",
                            " 'To': 12,\n",
                            " 'Then': 13,\n",
                            " 'fair': 14,\n",
                            " \"beauty's\": 15,\n",
                            " 'thou': 16,\n",
                            " 'weed': 17,\n",
                            " 'trenches': 18,\n",
                            " 'his': 19,\n",
                            " 'And': 20,\n",
                            " 'see': 21,\n",
                            " 'thriftless': 22,\n",
                            " 'treasure': 23,\n",
                            " 'shame,': 24,\n",
                            " 'count,': 25,\n",
                            " 'Proving': 26,\n",
                            " 'worth': 27,\n",
                            " 'new': 28,\n",
                            " 'when': 29,\n",
                            " \"totter'd\": 30,\n",
                            " 'praise': 31,\n",
                            " 'held:': 32,\n",
                            " 'deep': 33,\n",
                            " 'brow,': 34,\n",
                            " 'proud': 35,\n",
                            " 'How': 36,\n",
                            " 'asked,': 37,\n",
                            " 'of': 38,\n",
                            " 'within': 39,\n",
                            " 'an': 40,\n",
                            " 'small': 41,\n",
                            " \"feel'st\": 42,\n",
                            " 'When': 43,\n",
                            " 'thy': 44,\n",
                            " 'succession': 45,\n",
                            " 'own': 46,\n",
                            " 'cold.': 47,\n",
                            " 'to': 48,\n",
                            " 'thine!': 49,\n",
                            " 'field,': 50,\n",
                            " 'on': 51,\n",
                            " 'lies,': 52,\n",
                            " 'child': 53,\n",
                            " 'be': 54,\n",
                            " 'old': 55,\n",
                            " 'all-eating': 56,\n",
                            " 'make': 57,\n",
                            " 'all': 58,\n",
                            " 'sunken': 59,\n",
                            " 'praise.': 60,\n",
                            " 'much': 61,\n",
                            " 'gazed': 62,\n",
                            " 'my': 63,\n",
                            " 'dig': 64,\n",
                            " 'warm': 65,\n",
                            " 'Where': 66,\n",
                            " 'sum': 67,\n",
                            " 'Were': 68,\n",
                            " 'besiege': 69,\n",
                            " 'by': 70,\n",
                            " 'Shall': 71,\n",
                            " 'being': 72,\n",
                            " \"deserv'd\": 73,\n",
                            " 'blood': 74,\n",
                            " 'eyes,': 75,\n",
                            " 'lusty': 76,\n",
                            " 'use,': 77,\n",
                            " 'answer': 78,\n",
                            " 'a': 79,\n",
                            " 'where': 80,\n",
                            " 'more': 81,\n",
                            " \"excuse,'\": 82,\n",
                            " 'If': 83,\n",
                            " 'Thy': 84,\n",
                            " 'in': 85,\n",
                            " 'forty': 86,\n",
                            " 'shall': 87,\n",
                            " 'beauty': 88,\n",
                            " 'This': 89,\n",
                            " 'it': 90,\n",
                            " 'winters': 91,\n",
                            " 'thine': 92,\n",
                            " 'art': 93,\n",
                            " 'were': 94,\n",
                            " \"youth's\": 95,\n",
                            " 'say,': 96}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 10
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "class NGramLanguageModeler(nn.Module):\n",
                "\n",
                "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
                "        super(NGramLanguageModeler, self).__init__()\n",
                "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
                "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
                "        self.linear2 = nn.Linear(128, vocab_size)\n",
                "\n",
                "    def forward(self, inputs):\n",
                "        embeds = self.embeddings(inputs).view((1, -1))\n",
                "        out = F.relu(self.linear1(embeds))\n",
                "        out = self.linear2(out)\n",
                "        log_probs = F.log_softmax(out, dim=1)\n",
                "        return log_probs"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "losses = []\n",
                "loss_function = nn.NLLLoss()\n",
                "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
                "optimizer = optim.SGD(model.parameters(), lr=0.001)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "for epoch in range(10):\n",
                "    total_loss = 0\n",
                "    for context, target in ngrams:\n",
                "\n",
                "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
                "        # into integer indices and wrap them in tensors)\n",
                "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
                "\n",
                "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
                "        # new instance, you need to zero out the gradients from the old\n",
                "        # instance\n",
                "        model.zero_grad()\n",
                "\n",
                "        # Step 3. Run the forward pass, getting log probabilities over next\n",
                "        # words\n",
                "        log_probs = model(context_idxs)\n",
                "\n",
                "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
                "        # word wrapped in a tensor)\n",
                "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
                "\n",
                "        # Step 5. Do the backward pass and update the gradient\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
                "        total_loss += loss.item()\n",
                "    losses.append(total_loss)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "print(losses)  # The loss decreased every iteration over the training data!"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[518.0279240608215, 515.7042031288147, 513.3921675682068, 511.0924482345581, 508.80477476119995, 506.5275626182556, 504.2590973377228, 501.99819803237915, 499.74469804763794, 497.49769020080566]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "# To get the embedding of a particular word, e.g. \"beauty\"\n",
                "print(model.embeddings.weight[word_to_ix[\"beauty\"]])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([-0.9105, -0.1426,  0.3001,  1.4573,  0.2307, -0.1474, -0.6362,  0.3518,\n",
                        "        -0.0297, -0.5678], grad_fn=<SelectBackward>)\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.11",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.11 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "53bc26c3fdbec4bd6ebd68893b07f54171f76704c024cc725a4463474c0c570f"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}